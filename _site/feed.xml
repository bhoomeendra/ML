<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/ML/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/ML/" rel="alternate" type="text/html" /><updated>2023-06-05T01:37:26+05:30</updated><id>http://localhost:4000/ML/feed.xml</id><title type="html">ML techniques</title><subtitle>This repo contains the solutions of coding interview questions from various sources.
</subtitle><author><name>Bhoomeendra Singh Sisodiy</name></author><entry><title type="html">Biase Variance Tradeoff</title><link href="http://localhost:4000/ML/jekyll/2023-06-04-Biase_Variance_Tradeoff.html" rel="alternate" type="text/html" title="Biase Variance Tradeoff" /><published>2023-06-04T00:00:00+05:30</published><updated>2023-06-04T00:00:00+05:30</updated><id>http://localhost:4000/ML/jekyll/Biase_Variance_Tradeoff</id><content type="html" xml:base="http://localhost:4000/ML/jekyll/2023-06-04-Biase_Variance_Tradeoff.html"><![CDATA[<p><a href="https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html">Visit</a></p>

<p>When we talk about the Biase and Variance tradeoff we are talking about the error in the model and these are calculated on multiple(infinte) train and test splits of the data as these measures are statical in nature.</p>

<p><strong>Bias :</strong></p>

<p>Bias is the difference between the average prediction of all the models and the expected Label. The Dataset is also obtained from the a distribution \(P(X,y)\) so for a feature vectors X we a distribution of y which comes from \(P(\frac{Y}{X})\) which means we have to get the expected label from the distribution \(P(\frac{Y}{X})\).</p>

<p>The reason for High bias could be that the model is too simple. Being High bias means that the model is not able to capture the general trend in the data. Low Bias means that the model is able to capture the general trend in the data and is a good situtation to be in.</p>

<p><strong>Variance :</strong></p>

<p>Let’s say we have 50 models and we have to calculate the variance of the models. We calculate the variance of the model by calculating the variability in the output of the models with the formula of variance.</p>

<p>High variance means that the model is not able to generalize well on the data and is overfitting. This mean that if the model is trained on a different the predictions would change drastically. Low variance means that the model is able to generalize well on the data and is a good situation to be in.</p>

<p><strong>Tradeoff :</strong></p>

<p>Pursuing low bias requires increasing complexity which increases variance as now the model has room to overfit the data, and pursuing low variance requires decreasing complexity which increases bias.</p>]]></content><author><name>Bhoomeendra</name></author><category term="Jekyll" /><summary type="html"><![CDATA[Visit]]></summary></entry><entry><title type="html">SVM</title><link href="http://localhost:4000/ML/jekyll/2023-06-04-SVM.html" rel="alternate" type="text/html" title="SVM" /><published>2023-06-04T00:00:00+05:30</published><updated>2023-06-04T00:00:00+05:30</updated><id>http://localhost:4000/ML/jekyll/SVM</id><content type="html" xml:base="http://localhost:4000/ML/jekyll/2023-06-04-SVM.html"><![CDATA[<h3 id="svm-for-classification">SVM for Classification</h3>

<p>Let’s say we have +ve and -ve classes what SVM tries to do is find a hyperplane such that it maximizes the margin between the +ve and -ve classes.</p>

<p><strong>Geometric Intuition</strong></p>
<ol>
  <li>Convex hull of the +ve and -ve classes.</li>
  <li>Find the shortest line that connects the convex hulls of the +ve and -ve classes.</li>
  <li>The line that is perpendicular to the shortest line is the separating hyperplane that maximizes the margin between the +ve and -ve classes.</li>
</ol>

<h3 id="formulation">Formulation</h3>
<p>We assume a separating hyperplane of the form \(w^Tx + b = 0\) where \(w\) is the normal vector to the hyperplane and \(b\) is the bias. We assume that the +ve class is on one side of the hyperplane at distance d and the -ve class is on the other side of the hyperplane at a distance c these are the margins and are parallel to the separating hyperplan. We can write the equation of the margins as follows:</p>

\[w^Tx + b = d\]

\[w^Tx + b = -c\]

<p>we can divide the first equation by d and the second equation by c as in doesn’t change the formulation. Now Our goal is to maximize the margin between the margins. Which would be the same as minimizing \(\frac{2}{\left \| w \right \|}\).</p>

<p>Hence the Objective function becomes:</p>

\[w^*,b^* = \underset{w,b}{argmax}\left (\frac{2}{||w||}\right )\]

\[s.t \:\:\: y_i(w^Tx_i + b) \geq 1  \:\:\: \forall i\]

<p>The important part is that the data points which have to be linearly separable for the above formulation to work. But in real world data is not linearly separable so we introduce the concept of slack variables. The slack variables are the distance of the data points from the margins. The objective function becomes:</p>

\[w^*,b^* = \underset{w,b}{argmin}\left (\frac{||w||}{2}\right ) + C \frac{1}{n}\sum_{i}^{n}\varepsilon_i\]

\[s.t \:\:\: y_i(w^Tx_i + b) \geq 1 - \varepsilon_i  \:\:\: \forall i\]

<p>If we look at the formulation we have added a penalty for error in the earlier formulation error was not possible because of the constraints of the formulation which is equivalent to C being infinity. Now we have a tradeoff between the margin and the error. If we increase C we are penalizing the error more and if we decrease C we are penalizing the margin more.</p>

<p>We will convert the above formulation into a Lagrangian formulation and solve it using the Lagrangian multipliers. The Lagrangian formulation is as follows:</p>

\[L(w,b,\varepsilon,\alpha,\mu) = \frac{||w||^{2}}{2} + C \frac{1}{n}\sum_{i}^{n}\varepsilon_i - \sum_{i}^{n}\alpha_i(y_i(w^Tx_i + b) - 1 + \varepsilon_i) - \sum_{i}^{n}\mu_i\varepsilon_i\]

<p>We take the partial derivative of the Lagrangian formulation with respect to w,b and \(\varepsilon\) and equate them to 0. We get the following equations:</p>

\[w = \sum_{i}^{n}\alpha_iy_ix_i\]

\[0 = \sum_{i}^{n}\alpha_iy_i\]

\[\alpha_i = C - \mu_i\]

<p>We substitute the above equations in the Lagrangian formulation and we get the following formulation:</p>

\[L(w,b,\varepsilon,\alpha,\mu) = \sum_{i}^{n}\alpha_i - \frac{1}{2}\sum_{i}^{n}\sum_{j}^{n}\alpha_i\alpha_jy_iy_jx_i^Tx_j\]

\[s.t \:\:\: \sum_{i}^{n}\alpha_iy_i = 0\]

\[\alpha_i \geq 0\]

\[\mu_i \geq 0\]

\[\varepsilon_i \geq 0\]

\[0 = \sum_{i}^{n}\alpha_iy_i\]

\[0 = \sum_{i}^{n}\mu_i\varepsilon_i\]

<p>The \(L(w,b,\varepsilon,\alpha,\mu)\) looks the same as the formulation for the dual problem of the Hard SVM the only differece is the constrains. The constrains \(\alpha_i \geq 0\)  ,  \(\mu_i \geq 0\) and \(\alpha_i = C - \mu_i\) we combine these constrains and we get \(0 \leq \alpha_i \leq C\).</p>

<h3 id="model-prediction">Model Prediction</h3>

<p>One’s we have identified the support vectors we can calculate the prediction on test as follows:</p>

\[y = sign(\sum_{i}^{n}\alpha_iy_ix_i^Tx + b)\]

<p>As only the support vectors contribute to the prediction we only need to store the support vectors and the corresponding \(\alpha\) values.</p>

<p>The other important thing to note is that the dot product \(x_i^Tx_j\) can be replaced by a kernel function \(K(x_i,x_j)\).</p>

<h3 id="kernel-trick">Kernel Trick</h3>

<p>The kernel trick is a technique in which we can replace the dot product \(x_i^Tx_j\) with a kernel function \(K(x_i,x_j)\) which is a function which takes two vectors as input and outputs a scalar. The kernel function should satisfy the following properties:</p>

\[K(x_i,x_j) = K(x_j,x_i)\]

\[K(x_i,x_j) \geq 0\]

\[\sum_{i}^{n}\sum_{j}^{n}c_ic_jK(x_i,x_j) \geq 0\]

<p>i.e. Symmetric, Positive Semi-definite.</p>

<p>The kernel function can be used to calculate the similarity between two vectors in a higher dimensional space without actually calculating the dot product in the higher dimensional space.</p>

<p><strong>Example:</strong></p>

<h3 id="kernel-functions">Kernel Functions</h3>

<ol>
  <li>Linear Kernel: \(K(x_i,x_j) = x_i^Tx_j\)</li>
  <li>Polynomial Kernel: \(K(x_i,x_j) = (x_i^Tx_j + 1)^d\)</li>
  <li>Gaussian Kernel(rbf kernel): \(K(x_i,x_j) = exp(-\frac{ \left \|  x_i - x_j \right \| ^2}{2\sigma^2})\)</li>
</ol>

<p>Gaussian Kernel is the most commonly used kernel function. The hyperparameter \(\sigma\) is the bandwidth of the kernel function.This is seen as \(\left \|  x_i - x_j \right \| ^2\) is the squared distance between the two vectors. The hyperparameter \(\sigma\) controls the kernel function. If \(\sigma\) is small then the kernel function is very sensitive to the distance between the two vectors (only the vectors which have a distance almost zero will be considered similar) and if \(\sigma\) is large then the kernel function is not very sensitive to the distance between the two vectors. <a href="https://towardsdatascience.com/radial-basis-function-rbf-kernel-the-go-to-kernel-acf0d22c798a">Visit</a></p>

<h3 id="svm-for-regression">SVM for Regression</h3>

<p><a href="https://www.niser.ac.in/~smishra/teach/cs460/2020/lectures/lec13_1/">Visit</a></p>]]></content><author><name>Bhoomeendra</name></author><category term="Jekyll" /><summary type="html"><![CDATA[SVM for Classification]]></summary></entry><entry><title type="html">Logistic Regression</title><link href="http://localhost:4000/ML/jekyll/2023-05-08-Logistic_Regression.html" rel="alternate" type="text/html" title="Logistic Regression" /><published>2023-05-08T00:00:00+05:30</published><updated>2023-05-08T00:00:00+05:30</updated><id>http://localhost:4000/ML/jekyll/Logistic_Regression</id><content type="html" xml:base="http://localhost:4000/ML/jekyll/2023-05-08-Logistic_Regression.html"><![CDATA[<!-- #### What is Logistic Regression? -->

<p>Logistic regression is linear regression over the log odds or logit of the probability of input belonging to a class. The model choice in logistic regression is the logits of the probability are linearly dependent on the independent variable. But the problem we solve with this is the <strong>classification problem</strong>. The output of the model is the probability of the input belonging to a class.
\(logit(p) = log(\frac{p}{p+1})\)</p>

<p>The model is as follows:</p>

\[logit(p) = w^Tx + b\]

\[p = \frac{1}{1+e^{-(w^Tx+b)}}\]

\[p = \sigma(w^Tx+b)\]

<p>What sigmoid does is that it constrains the output between 0 and 1. This is one of the definitions of logistic regression.</p>
<h3 id="geometric-formulation">Geometric Formulation</h3>
<p>We can have a geometric explanation as well. We start with a classification boundary which is \(w^Tx +b\). We want a w such that \(\forall i \; y_i(w^Tx_i+b)&gt;=0\) i.e the predicted class and the actual class are of the same sign for the product term to be positive but using a objective function which maximizes \(\sum y_i(w^Tx_i+b)\) has some limitation. The problem is that when an outlier comes, the loss value will be very high, and the model will try to fit the outlier. To solve the problem sigmoid function is used as it constrains the values between 0 and 1 which limits the impact of outlier.</p>

<h3 id="formulation-of-the-loss-function">Formulation of the loss function</h3>
<p>The purpose of the loss function is to maximize the probability of the correct class. Logistic regression is a binary classification problem; hence we have two classes, 0 and 1. Higher probability is associated with class 1, and low probability is associated with class 0. The objective function is as follows:</p>

\[L = \prod_{i=1}^n p_i^{y_i}(1-p_i)^{1-y_i} \; where \; p = \sigma(w^Tx+b)\]

\[L = \prod_{i=1}^n \sigma(w^Tx_i+b)^{y_i}(1-\sigma(w^Tx_i+b))^{1-y_i}\]

<p>As all the values are always positive, taking log will not affect the optimization problem. Also will help with numerical stability as the probability values are very small and the product will be even smaller. Hence the loss function is as follows:</p>

\[L = \sum_{i=1}^n y_i log(\sigma(w^Tx_i+b)) + (1-y_i)log(1-\sigma(w^Tx_i+b))\]

\[w^* = argmax_w L(w)\]

<p>But still, we have a problem which is that if when w tends to infinity, the we would have the maximum value of the objective function, which is not what we want. Hence we add a regularization term to the objective function. The objective function is as follows:</p>

\[L =  \sum_{i=1}^n y_i log(\sigma(w^Tx_i+b)) + (1-y_i)log(1-\sigma(w^Tx_i+b)) + \lambda ww^T\]

<!-- This theme supports rendering beautiful math in inline and display modes using [MathJax 3](https://www.mathjax.org/) engine. You just need to surround your math expression with `$$`, like `$$ E = mc^2 $$`. If you leave it inside a paragraph, it will produce an inline expression, just like $$ E = mc^2 $$. -->

<!-- To use display mode, again surround your expression with `$$` and place it as a separate paragraph. Here is an example: -->

<!-- $$\sum_{k=1}^\infty |\langle x, e_k \rangle|^2 \leq \|x\|^2$$ -->

<h3 id="interview-questions">Interview Questions</h3>

<p>Should we normailze the data before giving it to the logistice regression algorithim?</p>

<p>Yes we should normalize the data it would give use two problems first is the</p>

<ul>
  <li>
    <p>Interpretiblity of the weights/coffecient</p>

    <ul>
      <li>Interpretiblity of the weights/coffecient as because the coffecient indicats the impact on prediction when we have unit change in the feature but feats with differect scale can not be compaired with each other once we normalize (Min Max) or standardize (\(\mu =0 , \sigma =1\)) the data becomes unitless hence comparative interpretblity is possible which could indicate geniune feature importance.</li>
    </ul>
  </li>
  <li>
    <p>Convergence of SGD</p>

    <ul>
      <li>The magnitude of gradient of depends on the values of the inputs which we can see for both squared loss and cross entorpy loss which mean that feature with higher values wil have bigger gradient and features with smaller values will have smaller gradient hence convergence would led to ossilation but when the data is normalized such problem is prevented.</li>
    </ul>
  </li>
</ul>]]></content><author><name>Bhoomeendra</name></author><category term="Jekyll" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Metrics</title><link href="http://localhost:4000/ML/jekyll/2023-05-08-Metrics.html" rel="alternate" type="text/html" title="Metrics" /><published>2023-05-08T00:00:00+05:30</published><updated>2023-05-08T00:00:00+05:30</updated><id>http://localhost:4000/ML/jekyll/Metrics</id><content type="html" xml:base="http://localhost:4000/ML/jekyll/2023-05-08-Metrics.html"><![CDATA[<h2 id="classification-metrics">Classification Metrics</h2>
<ol>
  <li>
    <p><strong>Accuracy:</strong></p>

    <p>This is the most simple measure, defined as the number of accurate predictions divided by the total number of predictions. This will not be a very good metric as if we have imbalanced class labels, then the metric will be biased towards the majority class. Also, when the problem is multi-class, accuracy will not be a good measure as it does not consider the class information.</p>
  </li>
  <li>
    <p><strong>Confusion Matrix:</strong></p>

    <p>This is a table that shows the number of correct and incorrect predictions made by the classification model compared to the actual outcomes (target value) in the data. The matrix is NxN, where N is the number of target values (classes). Performance of such models is commonly evaluated using the data in the matrix. This gives us a complete picture of how well our model works with respect to all the classes.</p>

    <p><strong>2x2 Confusion Matrix</strong></p>

    <p>The confusion matrix is for a binary classifier the ground truth are of two types True or False and the prediction can be of two types Positive or Negative. So, the confusion matrix will have 4 values TP, TN, FP, FN.</p>

    <p>TP: True Positive mean that when the ground truth is True and the prediction is positive.</p>

    <p>TN: True Negative mean that when the ground truth is True and the prediction is negative.</p>

    <p>FP: False Positive mean that when the ground truth is False and the prediction is positive.</p>

    <p>FN: False Negative mean that when the ground truth is False and the prediction is negative.</p>

    <table>
      <thead>
        <tr>
          <th> </th>
          <th>Prediction 1</th>
          <th>Prediction 0</th>
          <th>Groud Truth</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Label 1</td>
          <td>TP</td>
          <td>TN</td>
          <td>TP+TN</td>
        </tr>
        <tr>
          <td>Label 0</td>
          <td>FP</td>
          <td>FN</td>
          <td>FP+FN</td>
        </tr>
        <tr>
          <td>Predicted</td>
          <td>TP+FP</td>
          <td>TN+FN</td>
          <td> </td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <p><strong>Precision:</strong></p>

    <p>Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answers is of all the positive predictions, how many are actually positive. This metric is useful when the cost of False Positive is high. For example, in the case of death penalty, we would want to be very sure that the person is guilty before giving the death penalty. So, we would want to have a high precision.</p>

\[Precision = \frac{TP}{(TP+FP)}\]
  </li>
  <li>
    <p><strong>Recall:</strong></p>

    <p>Recall is the ratio of correctly predicted positive observations to all observations in the actual class. The question recall answers is: Of all the positive classes, how many did we predict correctly? It is also called Sensitivity. The recall is a good measure to use when the cost of True Negative is high. For example, in the case of a natural calamity, we would want to alert as many people as possible, a wrong alert is not harmful, but a missed alert can be very harmful.</p>

\[Recall = \frac{TP}{(TP+TN)}\]
  </li>
  <li>
    <p>\(F_\beta\) Score</p>

    <p>The \(F_\beta\) score is the weighted harmonic mean of precision and recall, reaching its optimal value at 1 and its worst value at 0. The \(F_\beta\) score weights recall more than precision by a factor of \(\beta\). \(\beta\) = 1.0 means recall and precision are equally important. for \(\beta &lt; 1.0\), precision is more important than recall and vice versa.</p>

\[F_{\beta} =  \frac{1}{ \frac{\beta^2}{1 + \beta^2} . \frac{1}{Recall} +  \frac{1}{1 + \beta^2} . \frac{1}{Precision} }\]

\[F_{\beta} = (1+\beta^2) \frac{Precision*Recall}{(\beta^2*Precision)+Recall}\]

    <p>When \(\beta\) = 1.0, it is called F1 score, which is the harmonic mean of precision and recall.</p>

\[F1 = 2 \frac{Precision*Recall}{Precision+Recall}\]

    <p>When \(\beta\) = 0.5, it is called F0.5 score, which is the weighted harmonic mean of precision and recall.</p>

\[F0.5 = \frac{1.25*Precision*Recall}{(0.25*Precision)+Recall}\]

    <p>When \(\beta\) = 2.0, it is called F2 score, which is the weighted harmonic mean of precision and recall.</p>

\[F2 = \frac{5*Precision*Recall}{(4*Precision)+Recall}\]

    <p><strong>F1 Score Multiclass Classification</strong></p>

    <ul>
      <li>
        <p><strong>F1 Macro</strong></p>

        <p>We have to calculate the F1 score for each class and then take the average of all the F1 scores. This is called F1 Macro.</p>
      </li>
      <li>
        <p><strong>F1 Micro</strong></p>

        <p>We have to calculate the F1 with the global information of total FP, FN and TP.</p>
      </li>
      <li>
        <p><strong>F1 Weighted</strong></p>

        <p>We have to calculate the F1 score for each class and then take the weighted average of all the F1 scores. Weights are the number of samples in each class or can be user defined.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>AUC ROC Curve:</strong> <em>Needs revision</em></p>

    <p>AUC ROC curve is a performance measurement for binary classification problems. ROC is a curve AUC is the area under the ROC curve. The ROC curve is a plot of the true positive rate (TPR) against the false positive rate (FPR) for a model which outputs probability. We use a threshold to predict the label, and these labels are used to calculate TPR and FPR. It shows the tradeoff between sensitivity and specificity. The closer the curve follows the upper left-hand border of the ROC space, the better the model (Why). The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test. The ROC curve is also called the receiver operating characteristic. The area under the ROC curve (AUC) is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one (assuming ‘positive’ ranks higher than ‘negative’).</p>
  </li>
</ol>

<h4 id="questions">Questions</h4>
<ol>
  <li>
    <p>What is the difference between accuracy and F1 score when the classes are balanced?</p>

    <p>Accuracy is the same as F1 macro score when the classes are balanced, but F1 micro will still give a better score as it give equal weightage to all the classes and overall accuracy might look good, but internally, the prediction for some classes might not be good. Both accuracy and F1 macro score will not capture this.</p>
  </li>
</ol>

<h2 id="regression-metrics">Regression Metrics</h2>
<ol>
  <li>
    <p><strong>Mean Absolute/Squared Error and Root Mean Squared Error</strong></p>

    <p>The mean absolute error (MAE) We’ll calculate the average absolute error between actual and predicted values. The mean squared error (MSE) is very similar to the MAE, but it squares the difference before summing them all instead of using the absolute value. This means that large errors are penalized more than with the MAE. The root mean squared error (RMSE) is the square root of the MSE. It’s more popular than MSE because the RMSE is interpretable in the “y” units.</p>
  </li>
  <li>
    <p><strong>R Squared</strong></p>

    <p>A dataset has n values marked \(y_1,..,y_n\) (collectively known as \(y_i\) or as a vector \(y = [y_1,...,y_n]^T\)), each associated with a fitted (or modeled, or predicted) value \(f_1,...,f_n\) (known as $f_i$, or sometimes \(\hat{y_i}\), as a vector f).</p>

    <p>Define the residuals as \(e_i = y_i − f_i\) (forming a vector e).</p>

    <p>If \(\bar {y}\) is the mean of the observed data
 then the variability of the data set can be measured with two sums of squares formulas:</p>

    <ul>
      <li>
        <p>The sum of squares of residuals also called the residual sum of squares:</p>

\[SS_{\text{res}}=\sum _{i}(y_{i}-f_{i})^{2}=\sum _{i}e_{i}^{2}\]
      </li>
      <li>
        <p>The total sum of squares (proportional to the variance of the data):</p>

\[SS_{\text{tot}}=\sum _{i}(y_{i}-{\bar {y}})^{2}\]
      </li>
    </ul>

    <p>The most general definition of the coefficient of determination is
 \(R^{2}=1-{SS_{\rm {res}} \over SS_{\rm {tot}}}\)</p>

    <p>In the best case, the modeled values exactly match the observed values, which results in \(SS_{\text{res}}=0\) and \(R^{2}=1\). A baseline model, which always predicts \(\bar {y}\), will have \(R^{2}=0\). Models that have worse predictions than this baseline will have a negative \(R^{2}\).</p>

    <p><strong>Fraction of variance unexplained</strong></p>

    <p>In a general form, \(R^{2}\) can be seen to be related to the fraction of variance unexplained (FVU). The numerator in the equation represents unexplained variance, while the denominator represents total variance. The FVU is the ratio of unexplained variance to total variance:</p>

\[R^{2}= \frac{ SS_{\rm {tot}} - SS_{\rm {res} }}{ SS_{\rm {tot}}}\]

    <p><strong>Inflated R2</strong></p>

    <p>When we add a new estimator or variable into the regression model \(R^{2}\) goes up or at least will stay the same which not good because comparing models with different numbers of features will not be feasible with \(R^{2}\). <a href="https://math.stackexchange.com/questions/1976747/prove-that-r2-cannot-decrease-when-adding-a-variable">Proof 2</a></p>
  </li>
  <li>
    <p><strong>Adjusted R Squared:</strong></p>

    <p>The use of an adjusted \(R^{2}\) (one common notation is \({\bar R}^{2}\), pronounced “R bar squared”; another is \(R_{\text{a}}^{2}\) or \(R_{\text{adj}}^{2}\)) is an attempt to account for the phenomenon of the \(R^{2}\) automatically increasing when extra explanatory variables are added to the model. There are many different ways of adjusting ([14]). By far the most used one, to the point that it is typically just referred to as adjusted R, is the correction proposed by Mordecai Ezekiel. The adjusted \(R^{2}\) is defined as</p>

\[{\bar {R}}^{2}={1-{SS_{\text{res}}/{\text{df}}_{\text{res}} \over SS_{\text{tot}}/{\text{df}}_{\text{tot}}}}\]

    <p>where dfres is the degrees of freedom of the estimate of the population variance around the model, and dftot is the degrees of freedom of the estimate of the population variance around the mean. dfres is given in terms of the sample size n and the number of variables p in the model, dfres =n − p. dftot is given in the same way, but with p being unity for the mean, i.e. dftot = n − 1.</p>

    <p>The adjusted  \(R^{2}\) can be negative, and its value will always be less than or equal to that of \(R^{2}\).</p>
  </li>
</ol>

<h2 id="retrieval-metrics">Retrieval Metrics</h2>
<ol>
  <li>
    <p><strong>MAP</strong></p>
  </li>
  <li>
    <p><strong>NDCG</strong></p>
  </li>
  <li>
    <p><strong>Precision@K</strong></p>
  </li>
  <li>
    <p><strong>Recall@K</strong></p>
  </li>
  <li>
    <p><strong>MRR</strong></p>
  </li>
  <li>
    <p><strong>BPREF</strong>
https://www.pinecone.io/learn/offline-evaluation/</p>
  </li>
</ol>

<h2 id="summarization-metrics">Summarization Metrics</h2>
<ol>
  <li>
    <p><strong>ROUGE</strong></p>
  </li>
  <li>
    <p><strong>BLEU</strong></p>
  </li>
  <li>
    <p><strong>METEOR</strong></p>
  </li>
  <li>
    <p><strong>BERTScore</strong></p>
  </li>
  <li>
    <p><strong>Perplexity</strong></p>
  </li>
</ol>

<h2 id="clustering-metrics">Clustering Metrics</h2>
<ol>
  <li>
    <p><strong>Silhouette Score</strong></p>
  </li>
  <li>
    <p><strong>Inter and Intra Cluster Distance ratio</strong></p>
  </li>
</ol>

<h2 id="segmentation-metrics">Segmentation Metrics</h2>

<ol>
  <li>
    <p><strong>IoU</strong></p>
  </li>
  <li>
    <p><strong>Precision</strong></p>
  </li>
  <li>
    <p><strong>Recall</strong></p>
  </li>
  <li>
    <p><strong>F1 Score</strong></p>
  </li>
  <li>
    <p><strong>MAP</strong></p>
  </li>
</ol>]]></content><author><name>Bhoomeendra</name></author><category term="Jekyll" /><summary type="html"><![CDATA[Classification Metrics Accuracy:]]></summary></entry><entry><title type="html">Regularization</title><link href="http://localhost:4000/ML/jekyll/2023-05-08-Regularization.html" rel="alternate" type="text/html" title="Regularization" /><published>2023-05-08T00:00:00+05:30</published><updated>2023-05-08T00:00:00+05:30</updated><id>http://localhost:4000/ML/jekyll/Regularization</id><content type="html" xml:base="http://localhost:4000/ML/jekyll/2023-05-08-Regularization.html"><![CDATA[]]></content><author><name>Bhoomeendra</name></author><category term="Jekyll" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Linear Regression</title><link href="http://localhost:4000/ML/jekyll/2023-05-08-Linear-Regression.html" rel="alternate" type="text/html" title="Linear Regression" /><published>2023-05-08T00:00:00+05:30</published><updated>2023-05-08T00:00:00+05:30</updated><id>http://localhost:4000/ML/jekyll/Linear%20Regression</id><content type="html" xml:base="http://localhost:4000/ML/jekyll/2023-05-08-Linear-Regression.html"><![CDATA[<!-- #### What is Linear Regression? -->
<p>The linear regression establishes a relationship between the dependent variable (y) and one or more independent variables (x) using a best-fit straight line. This means relationship between the dependent and independent variables is linear in nature.</p>

<h4 id="different-ways-to-solve-linear-regression">Different ways to solve Linear Regression</h4>
<ol>
  <li>
    <p><strong>Normal Equation:</strong> The normal equation is a closed-form solution for linear regression (Gaussian Elimination). It finds the value of the regression coefficients that minimizes the sum of the squared residuals.</p>
  </li>
  <li>
    <p><strong>Gradient Descent:</strong> Gradient descent is an iterative optimization algorithm that can be used to solve linear regression. It works by finding the minimum of a cost function, which is typically the sum of the squared residuals.</p>
  </li>
  <li>
    <p><strong>Singular Value Decomposition:</strong> The SVD is used because the data matrix is non-invertible hence we calcute its pseudo-inverse using SVD this is a great artricle explaning the same <a href="https://sthalles.github.io/svd-for-regression/">Visit</a>.</p>
  </li>
</ol>

<h4 id="checks-to-apply-before-applying-linear-regression">Checks to apply before applying Linear Regression</h4>
<ol>
  <li><strong>Linearity:</strong> Linear relationship between dependent and independent variables that can be done using person correlation coefficient not the spearman correlation coefficient.</li>
  <li><strong>Normality:</strong> The residuals are normally distributed. This means that the residuals follow a bell-shaped curve, with most of the values clustered around the mean. The normality assumption is necessary because it allows us to use the standard techniques of statistical inference, such as hypothesis testing and confidence intervals. Violations of normality can lead to biased and inefficient estimates, and incorrect conclusions about the statistical significance of the independent variables.</li>
  <li><strong>Homoscedasticity:</strong> The distribution of residual should be same for all the values of independent variable because if the errors are dependent on the value of independent variable then the model is uncertain as some inputs and is certian at some inputs. This does not provide us a concrete prediction hence the model is not very reiable.</li>
  <li><strong>No multicollinearity:</strong> There is no high correlation between the independent variables. This means that the independent variables are not too closely related to each other.  If there is high correlation between the independent variables, it can be difficult to separate out their individual effects on the dependent variable, leading to unstable estimates of the regression coefficients.</li>
</ol>

<h4 id="how-to-deal-with-multicollinearity">How to deal with multicollinearity?</h4>
<ol>
  <li><strong>Remove one of the correlated variables:</strong> The simplest way to deal with multicollinearity is to remove one of the highly correlated variables from the regression model. The downside of this approach is that it reduces the degrees of freedom of the model, which can weaken the statistical power of your analysis.</li>
  <li><strong>Combine the correlated variables:</strong> Another way to deal with multicollinearity is to combine the correlated variables together to form a single predictor. For example, if you had two highly correlated variables, you could combine them together to form a single predictor by taking their average.</li>
  <li><strong>Use principal components:</strong> Principal components analysis (PCA) is a dimension reduction technique that can be used to reduce a large set of variables to a small set that still contains most of the information in the large set. This technique is useful when you have a large number of correlated predictors, and you want to summarize them with a smaller set of representative variables.</li>
  <li><strong>Use regularization methods:</strong> Regularization methods, such as ridge (L2 regularization) regression and lasso regression( L1 Regularization), are powerful techniques that are designed to deal with multicollinearity by constraining the size of the regression coefficients. These methods work well when you have a large number of correlated predictors.</li>
  <li><strong>Do nothing:</strong> If your goal is to make predictions, and not to understand the role of each individual variable, then multicollinearity might not be a problem. Multicollinearity only affects the interpretation of your model if you care about the specific role of each variable. However, multicollinearity does affect the precision of the estimated regression coefficients, which can cause your predictions to be less reliable.</li>
  <li><strong>Use Partial Least Squares Regression:</strong> Partial least squares regression (PLS regression) is a regression method that is an alternative to ordinary least squares (OLS) regression. PLS regression is useful when you have a large number of correlated predictors, and you want to use them to predict an outcome, but you also want to reduce the number of predictors in your model. PLS regression is similar to principal components regression, but the key difference between the two methods is that PLS regression uses the response variable in the dimension reduction step, while principal components regression does not.</li>
</ol>

<h4 id="what-is-the-difference-between-l1-and-l2-regularization">What is the difference between L1 and L2 regularization?</h4>
<p>L2 regularization is also known as ridge regression. L1 also known as Lasso. The key difference between them is when we take derivative of the loss function for both, In L2 we see the update or change would be 2*coeff but in L1 it would be either 1 or -1. This is the reason why L1 regularization is used for feature selection and drives some of the coefficients to zero. <a href="https://medium.com/@mukulranjan/how-does-lasso-regression-l1-encourage-zero-coefficients-but-not-the-l2-20e4893cba5d">Visit</a></p>

<h1 id="interview-questions">Interview Questions</h1>]]></content><author><name>Bhoomeendra</name></author><category term="Jekyll" /><summary type="html"><![CDATA[The linear regression establishes a relationship between the dependent variable (y) and one or more independent variables (x) using a best-fit straight line. This means relationship between the dependent and independent variables is linear in nature.]]></summary></entry><entry><title type="html">Decision Tree</title><link href="http://localhost:4000/ML/jekyll/2023-05-08-Decision_Tree.html" rel="alternate" type="text/html" title="Decision Tree" /><published>2023-05-08T00:00:00+05:30</published><updated>2023-05-08T00:00:00+05:30</updated><id>http://localhost:4000/ML/jekyll/Decision_Tree</id><content type="html" xml:base="http://localhost:4000/ML/jekyll/2023-05-08-Decision_Tree.html"><![CDATA[<!-- #### What is Decision Tree? -->
<p>Decision tree is a type of supervised learning algorithm that can be used for classification and regression the the algorith tries to split the data into different groups based on the features such that it maximizes the information gain or minimizes the entropy. We will take the example of classification to understand the decision tree.</p>
<h3 id="algorithm">Algorithm:</h3>

<ol>
  <li>
    <p>We start with the root node which has all the data points. Now the first step is to split the root node based on the feature the question is how do we decide which feature is a good feature? We use the concept of information gain to decide which feature is a good feature.</p>

    <p><strong>Information Gain</strong>
 Let’s say we have a feature called color which has 3 values red, blue and green. Now we want to split the data based on this feature. When we split the node based on color we would get three children. We calculate the entropy of the root node and then we calculate the entropy of the child nodes. The entropy of the root node is calculated as follows:</p>

\[Entropy = -\sum_{i=1}^{n} p_i \log_{2}(p_i)\]

    <p>where $p_i$ is the probability of the class $i$ in the root node. Now we calculate the entropy of the child nodes. The entropy of the child nodes is calculated as follows:</p>

\[Child Entropy =   - \sum_{j=1}^{C}\frac{n_j}{n}*\sum_{i=1}^{n_j} p_{ji} \log_{2}(p_{ji})\]

    <p>where $p_{ji}$ is the probability of the class $i$ in the child node \(j\). \(\frac{n_j}{n}\) gives the fraction of data points in a given child node compared to the root node. Now we calculate the information gain as follows:</p>

\[Information Gain = Entropy - Child Entropy\]
  </li>
  <li>
    <p>We calculate the information gain for all the features and we select the feature which has the highest information gain. We split the root node based on this feature.</p>
  </li>
  <li>
    <p>We Repeat the above steps for all the child nodes until we get pure or mixed node to a certain amount or we reach the maximum depth of the tree.</p>
  </li>
</ol>

<p><strong>Spliting Criteria for Numerical features</strong></p>

<p>Let’s say we have a feature which is numerical and we want to split the data based on this feature. We first find all the unique values numerical data and sort them, then we find all the mid points between the consecutive values these would be cadidate threshold values. We calculate the information gain for all the threshold values and we select the one which gives the highest information gain.</p>

<p><strong>Stopping Criteria</strong></p>
<ol>
  <li>We stop when we reach the maximum depth of the tree.</li>
  <li>We stop when we reach the minimum number of data points in a leaf node.</li>
  <li>We stop when we reach the minimum information gain.</li>
</ol>

<p><strong>Pruning</strong>
Pruning is a technique in which we remove the nodes which do not add any value to the model.</p>

<p><strong>Gini Index</strong>
Gini index is a measure of impurity. It is calculated as follows:</p>

\[Gini Index = 1 - \sum_{i=1}^{n} p_i^2\]

<p>where $p_i$ is the probability of the class $i$ in the node.</p>

<p><strong>Pros</strong></p>

<ol>
  <li>Decision tree is easy to interpret.</li>
  <li>Decision tree can handle both numerical and categorical data.</li>
  <li>Minimal impact of outliers.</li>
  <li>Decision tree can be used for feature selection.</li>
  <li>Decision tree can be used for regression and classification.</li>
  <li>Normalization and scaling of data is not required.</li>
</ol>

<p><strong>Cons</strong></p>

<ol>
  <li>Decision tree is prone to overfitting.</li>
  <li>Decision tree is unstable, small changes in the data can lead to large changes in the structure of the decision tree.</li>
  <li>Decision tree can create biased trees if some classes dominate.</li>
</ol>

<h3 id="regression-tree">Regression Tree</h3>
<p>We minimize the sum of squared error at each split. And the prediction is the mean of the data points in the leaf node.</p>

<ol>
  <li>
    <p>For the first node the mean of the data would be the prediction. Now we will select a feature and threshold combination which will reduce the sum of squared error the most.</p>
  </li>
  <li>
    <p>We repeat the above step for all the child nodes until we reach the maximum depth of the tree or we reach the minimum number of data points in a leaf node.</p>
  </li>
</ol>]]></content><author><name>Bhoomeendra</name></author><category term="Jekyll" /><summary type="html"><![CDATA[Decision tree is a type of supervised learning algorithm that can be used for classification and regression the the algorith tries to split the data into different groups based on the features such that it maximizes the information gain or minimizes the entropy. We will take the example of classification to understand the decision tree. Algorithm:]]></summary></entry></feed>